{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec251dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timeautoencoder as tae\n",
    "import timediffusion_cond as ctdf\n",
    "import DP as dp\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import process_edited as pce\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dff00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'Data/nasdaq.csv'\n",
    "# Read dataframe\n",
    "print(filename)\n",
    "real_df = pd.read_csv(filename)\n",
    "real_df1 = real_df.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a397dedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458a92efe80b43ba83891d11e5649965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Namjoon Suh\\TimeTabularDiff\\timeautoencoder.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  angles = torch.tensor(2**torch.arange(num_terms).float().to(device) * torch.tensor(math.pi).to(device) * v.unsqueeze(-1)).to(device)\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################################\n",
    "# Pre-processing Data\n",
    "threshold = 1; device = 'cuda'; column_to_partition = 'Symbol'\n",
    "processed_data, time_info = dp.partition_multi_seq(real_df, threshold, column_to_partition);\n",
    "\n",
    "##################################################################################################################\n",
    "# Auto-encoder Training\n",
    "n_epochs = 20000; eps = 1e-5\n",
    "weight_decay = 1e-6 ; lr = 2e-4; hidden_size = 200; num_layers = 1; batch_size = 50\n",
    "channels = 64; min_beta = 1e-5; max_beta = 0.1; emb_dim = 128; time_dim = 8\n",
    "lat_dim = 7; seq_col = 'Symbol'\n",
    "real_df1 = real_df1.drop(column_to_partition, axis=1)\n",
    "\n",
    "ds = tae.train_autoencoder(real_df1, processed_data, time_info.to(device), channels, hidden_size, num_layers, lr, weight_decay, n_epochs, \\\n",
    "                           batch_size, threshold,  min_beta, max_beta, emb_dim, time_dim, lat_dim, device)\n",
    "\n",
    "##################################################################################################################\n",
    "# Diffusion Training\n",
    "latent_features = ds[1];\n",
    "hidden_dim = 250; num_layers = 2; diffusion_steps = 100; n_epochs = 20000; num_classes = len(latent_features)\n",
    "diff = ctdf.train_diffusion(latent_features, time_info.to(device), hidden_dim, num_layers, diffusion_steps, n_epochs, num_classes)\n",
    "\n",
    "##################################################################################################################\n",
    "# Sampling time-series tabular data of 8th entity \n",
    "N, T, _ = processed_data.shape; \n",
    "\n",
    "_, time_info = dp.partition_multi_seq(real_df, threshold, column_to_partition);\n",
    "\n",
    "lbl = torch.arange(0, len(latent_features));  # Generate the entire Sequence  \n",
    "label = torch.repeat_interleave(lbl, T, dim=0).reshape(len(lbl),T)\n",
    "\n",
    "label=[8]; # 8th \n",
    "latent_features = latent_features[label,:,:]\n",
    "time_info = time_info[label,:,:]\n",
    "\n",
    "N, _, _ = latent_features.shape\n",
    "t_grid = torch.linspace(0, 1, T).view(1, -1, 1).to(device) \n",
    "\n",
    "samples = ctdf.sample(t_grid.repeat(N, 1, 1), latent_features.detach().to(device), diff, time_info, label, cfg_scale = 3)\n",
    "\n",
    "##################################################################################################################\n",
    "# Post-process the generated data \n",
    "gen_output = ds[0].decoder(samples.to(device))  # Apply decoder to generated latent vector\n",
    "\n",
    "data_size, seq_len, _ = latent_features.shape\n",
    "synth_data = pce.convert_to_tensor(real_df1, gen_output, threshold, data_size, seq_len)\n",
    "_synth_data = pce.convert_to_table(real_df1, synth_data, threshold)\n",
    "\n",
    "##################################################################################################################\n",
    "# Draw the plots for marginal of featueres : Real v.s. Synthetic\n",
    "_real_data = pce.convert_to_table(real_df1, processed_data[label,:,:], threshold)\n",
    "\n",
    "# To see if you want to check real-data are recovered well.\n",
    "B, L, K = _synth_data.shape\n",
    "\n",
    "sd_reshaped = _synth_data.reshape(B * L, K)\n",
    "pd_reshaped = _real_data.reshape(B * L, K)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(nrows=1, ncols=K, figsize=(20, 3))\n",
    "column_names = real_df1.columns.tolist()\n",
    "\n",
    "for k in range(0,K):\n",
    "    title = column_names[k]\n",
    "    \n",
    "    axes[k].hist(pd_reshaped[:,k].cpu().detach(), bins=50, color='blue', alpha=0.5, label='Real')\n",
    "    axes[k].hist(sd_reshaped[:,k].cpu().detach(), bins=50, color='red', alpha=0.5, label='Synthetic')\n",
    "    \n",
    "    # Move the legend line inside the with statement\n",
    "    axes[k].legend()\n",
    "    axes[k].set_title(title)\n",
    "\n",
    "# Adjust layout to prevent overlapping titles\n",
    "plt.tight_layout()\n",
    "plt.savefig('nasdaq.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
