{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3181937e-aa43-41ca-87ed-1a42392a6aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import dataprovider as dp\n",
    "import process_edited as pce\n",
    "import matplotlib.pyplot as plt\n",
    "from dataprovider_pypots import ImpPypots, MultiImpPypots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a151bc-d1ea-479d-a18a-88b47640d6ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = 'dataset/bike_sharing'\n",
    "filename = f'{data}.csv'\n",
    "real_df = pd.read_csv(filename)\n",
    "\n",
    "cols = real_df.columns.to_list()\n",
    "cols[1] = \"date\" \n",
    "real_df.columns = cols\n",
    "\n",
    "real_df = real_df.drop(columns=[\"instant\", \"yr\", \"mnth\"])\n",
    "\n",
    "# ImpPypots를 사용한 데이터셋 생성\n",
    "data = ImpPypots(real_df,\n",
    "                 train_ratio=0.8,\n",
    "                 val_ratio=0.1,\n",
    "                 test_ratio=0.1,\n",
    "                 seq_len=48,\n",
    "                 stride=12,\n",
    "                 rate=0.01,\n",
    "                 pattern=\"block\", #\"point\", \"subseq\", \"block\"\n",
    "                 sub_seq_len=12,\n",
    "                 block_len=3,\n",
    "                 block_width=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c306760f-3015-441e-9213-641b484630f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4573f75a06b94775a70cead09a959764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m; lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2e-4\u001b[39m; hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m; num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m; batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     10\u001b[0m channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m; min_beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m; max_beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m; emb_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m; time_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m; threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m; device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_df1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_beta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_beta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m latent_features \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m diff_training; hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m; num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m; diffusion_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m; num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(latent_features)\n",
      "File \u001b[0;32m/workspace/TimeAutoDiff/VAE.py:321\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(real_df, channels, hidden_size, num_layers, lr, weight_decay, n_epochs, batch_size, threshold, min_beta, max_beta, emb_dim, time_dim, lat_dim, device, data_dict)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# ---- training minibatch ----\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     ae\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 321\u001b[0m     batch_idx \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# fresh view each epoch in case dict changed\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     tgt_train  \u001b[38;5;241m=\u001b[39m data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_train\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/lib/python3.12/random.py:430\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    428\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    431\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m    432\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "import VAE as vae\n",
    "import DIFF as diff\n",
    "\n",
    "VAE_training = 25000; diff_training = 30000; lat_dim = 6; \n",
    "real_df1 = real_df.drop(['date'], axis=1)\n",
    "\n",
    "######################## Auto-encoder Training ########################\n",
    "n_epochs = VAE_training; eps = 1e-5\n",
    "weight_decay = 1e-6; lr = 2e-4; hidden_size = 512; num_layers = 2; batch_size = 100\n",
    "channels = 64; min_beta = 1e-5; max_beta = 0.1; emb_dim = 128; time_dim = 8; threshold = 1; device = 'cuda'\n",
    "ds = vae.train_autoencoder(real_df1, channels, hidden_size, num_layers, lr, weight_decay, n_epochs, batch_size, threshold, min_beta, max_beta, emb_dim, time_dim, lat_dim, device, data_dict)\n",
    "latent_features = ds[1]\n",
    "\n",
    "n_epochs = diff_training; hidden_dim = 512; num_layers = 2; diffusion_steps = 100; num_classes = len(latent_features)\n",
    "diff = diff.train_diffusion(latent_features, real_df1, data_dict, hidden_dim, num_layers, diffusion_steps, n_epochs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c2bb9-ca40-4e6d-9b64-21f037a002ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Evaluation.Metrics as mt\n",
    "import DIFF as Diff\n",
    "from pypots.nn.functional import calc_mae\n",
    "\n",
    "target_mask_test=data_dict['target_mask_test']\n",
    "target_test=data_dict['response_test']\n",
    "cond_test=data_dict['cond_test']\n",
    "time_info_test=data_dict['time_info_test']\n",
    "\n",
    "# Sampling process\n",
    "device = 'cuda'\n",
    "diffusion_steps = 100\n",
    "Batch_size, Seq_len, _ = target_test.shape\n",
    "Lat_dim = lat_dim\n",
    "t_grid = torch.linspace(0, 1, Seq_len).view(1, -1, 1).to(device)\n",
    "samples = Diff.sample(\n",
    "    t_grid.repeat(Batch_size, 1, 1),\n",
    "    Batch_size,\n",
    "    Seq_len,\n",
    "    Lat_dim,\n",
    "    diffusion_steps,\n",
    "    diff,\n",
    "    time_info_test,\n",
    "    cond_test,\n",
    "    target_mask_test.float().to(device),\n",
    ")\n",
    "\n",
    "# Process the generated data\n",
    "gen_output = ds[0].decoder(samples.to(device), target_mask_test, cond_test)\n",
    "_synth_data = pce.convert_to_tensor(real_df1, gen_output, 1, Batch_size, Seq_len)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "mae = calc_mae(_synth_data.to('cpu').numpy(), target_test.to('cpu').numpy(), target_mask_test.numpy())\n",
    "mse = F.mse_loss(_synth_data.to('cpu'), target_test.to('cpu'), reduction='mean').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e957bb8-612b-4da2-8525-43e2899baf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mae, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de3496-8279-4b44-8bff-b210c69565a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "##################################################################################################################\n",
    "label = 3\n",
    "entire_data = target_test + cond_test\n",
    "\n",
    "# Create a letter-sized figure\n",
    "fig, axes = plt.subplots(entire_data.shape[2], 1, figsize=(8.5, 11), constrained_layout=True)  \n",
    "parser = pce.DataFrameParser().fit(real_df1, threshold=1)\n",
    "column_name = parser.column_name()\n",
    "\n",
    "# Plot time series for each column\n",
    "for i in range(entire_data.shape[2]):\n",
    "    # Get data for plotting\n",
    "    ground_truth = entire_data[label, :, i].numpy()  # Ensure it's a NumPy array\n",
    "    ground_truth_missing = target_test[label, :, i].numpy()  # Ensure it's a NumPy array\n",
    "    imputed_values = _synth_data[label, :, i].cpu().numpy()  # Ensure it's a NumPy array\n",
    "    \n",
    "    # Identify missing entries (1 indicates missing data)\n",
    "    missing_entries = np.array(target_mask_test[label, :, i], dtype=bool)\n",
    "    time_indices = np.arange(len(ground_truth))  # Generate integer indices\n",
    "    \n",
    "    # Plot the real data (Ground-truth Observed)\n",
    "    axes[i].scatter(\n",
    "        time_indices[~missing_entries],\n",
    "        ground_truth[~missing_entries],\n",
    "        color='b',\n",
    "        marker='o',\n",
    "        #label=f'Ground-truth observed-entries {column_name[i]}'\n",
    "    )\n",
    "    \n",
    "    # Plot the missing entries (Ground-truth Missing)\n",
    "    axes[i].scatter(\n",
    "        time_indices[missing_entries],\n",
    "        ground_truth[missing_entries],\n",
    "        color='g',\n",
    "        marker='o',\n",
    "        #label=f'Ground-truth missing-entries {column_name[i]}'\n",
    "    )\n",
    "    \n",
    "    # Plot the missing entries (Ground-truth Missing)\n",
    "    axes[i].scatter(\n",
    "        time_indices[missing_entries],\n",
    "        imputed_values[missing_entries],\n",
    "        color='r',\n",
    "        marker='x',\n",
    "        #label=f'Imputed-entries {column_name[i]}'\n",
    "    )\n",
    "    \n",
    "    axes[i].set_xlabel('Time')\n",
    "    axes[i].set_ylabel(f'{column_name[i]}')\n",
    "    axes[i].grid(True)\n",
    "    axes[i].legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b07171-e6fe-4f4a-8c83-1f178234852f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
