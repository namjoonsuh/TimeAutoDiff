{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181937e-aa43-41ca-87ed-1a42392a6aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import dataprovider as dp\n",
    "import process_edited as pce\n",
    "import matplotlib.pyplot as plt\n",
    "from dataprovider_pypots import ImpPypots, MultiImpPypots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a151bc-d1ea-479d-a18a-88b47640d6ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = 'dataset/bike_sharing'\n",
    "filename = f'{data}.csv'\n",
    "real_df = pd.read_csv(filename)\n",
    "\n",
    "cols = real_df.columns.to_list()\n",
    "cols[1] = \"date\" \n",
    "real_df.columns = cols\n",
    "\n",
    "real_df = real_df.drop(columns=[\"instant\", \"yr\", \"mnth\"])\n",
    "\n",
    "# ImpPypots를 사용한 데이터셋 생성\n",
    "data = ImpPypots(real_df,\n",
    "                 train_ratio=0.8,\n",
    "                 val_ratio=0.1,\n",
    "                 test_ratio=0.1,\n",
    "                 seq_len=48,\n",
    "                 stride=12,\n",
    "                 rate=0.01,\n",
    "                 pattern=\"block\", #\"point\", \"subseq\", \"block\"\n",
    "                 sub_seq_len=12,\n",
    "                 block_len=3,\n",
    "                 block_width=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306760f-3015-441e-9213-641b484630f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import VAE as vae\n",
    "import DIFF as diff\n",
    "\n",
    "VAE_training = 25000; diff_training = 30000; lat_dim = 6; \n",
    "real_df1 = real_df.drop(['date'], axis=1)\n",
    "\n",
    "######################## Auto-encoder Training ########################\n",
    "n_epochs = VAE_training; eps = 1e-5\n",
    "weight_decay = 1e-6; lr = 2e-4; hidden_size = 512; num_layers = 2; batch_size = 100\n",
    "channels = 64; min_beta = 1e-5; max_beta = 0.1; emb_dim = 128; time_dim = 8; threshold = 1; device = 'cuda'\n",
    "ds = vae.train_autoencoder(real_df1, channels, hidden_size, num_layers, lr, weight_decay, n_epochs, batch_size, threshold, min_beta, max_beta, emb_dim, time_dim, lat_dim, device, data_dict)\n",
    "latent_features = ds[1]\n",
    "\n",
    "n_epochs = diff_training; hidden_dim = 512; num_layers = 2; diffusion_steps = 100; num_classes = len(latent_features)\n",
    "diff = diff.train_diffusion(latent_features, real_df1, data_dict, hidden_dim, num_layers, diffusion_steps, n_epochs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c2bb9-ca40-4e6d-9b64-21f037a002ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Evaluation.Metrics as mt\n",
    "import DIFF as Diff\n",
    "from pypots.nn.functional import calc_mae\n",
    "\n",
    "target_mask_test=data_dict['target_mask_test']\n",
    "target_test=data_dict['response_test']\n",
    "cond_test=data_dict['cond_test']\n",
    "time_info_test=data_dict['time_info_test']\n",
    "\n",
    "# Sampling process\n",
    "device = 'cuda'\n",
    "diffusion_steps = 100\n",
    "Batch_size, Seq_len, _ = target_test.shape\n",
    "Lat_dim = lat_dim\n",
    "t_grid = torch.linspace(0, 1, Seq_len).view(1, -1, 1).to(device)\n",
    "samples = Diff.sample(\n",
    "    t_grid.repeat(Batch_size, 1, 1),\n",
    "    Batch_size,\n",
    "    Seq_len,\n",
    "    Lat_dim,\n",
    "    diffusion_steps,\n",
    "    diff,\n",
    "    time_info_test,\n",
    "    cond_test,\n",
    "    target_mask_test.float().to(device),\n",
    ")\n",
    "\n",
    "# Process the generated data\n",
    "gen_output = ds[0].decoder(samples.to(device), target_mask_test, cond_test)\n",
    "_synth_data = pce.convert_to_tensor(real_df1, gen_output, 1, Batch_size, Seq_len)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "mae = calc_mae(_synth_data.to('cpu').numpy(), target_test.to('cpu').numpy(), target_mask_test.numpy())\n",
    "mse = F.mse_loss(_synth_data.to('cpu'), target_test.to('cpu'), reduction='mean').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e957bb8-612b-4da2-8525-43e2899baf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mae, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de3496-8279-4b44-8bff-b210c69565a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "##################################################################################################################\n",
    "label = 3\n",
    "entire_data = target_test + cond_test\n",
    "\n",
    "# Create a letter-sized figure\n",
    "fig, axes = plt.subplots(entire_data.shape[2], 1, figsize=(8.5, 11), constrained_layout=True)  \n",
    "parser = pce.DataFrameParser().fit(real_df1, threshold=1)\n",
    "column_name = parser.column_name()\n",
    "\n",
    "# Plot time series for each column\n",
    "for i in range(entire_data.shape[2]):\n",
    "    # Get data for plotting\n",
    "    ground_truth = entire_data[label, :, i].numpy()  # Ensure it's a NumPy array\n",
    "    ground_truth_missing = target_test[label, :, i].numpy()  # Ensure it's a NumPy array\n",
    "    imputed_values = _synth_data[label, :, i].cpu().numpy()  # Ensure it's a NumPy array\n",
    "    \n",
    "    # Identify missing entries (1 indicates missing data)\n",
    "    missing_entries = np.array(target_mask_test[label, :, i], dtype=bool)\n",
    "    time_indices = np.arange(len(ground_truth))  # Generate integer indices\n",
    "    \n",
    "    # Plot the real data (Ground-truth Observed)\n",
    "    axes[i].scatter(\n",
    "        time_indices[~missing_entries],\n",
    "        ground_truth[~missing_entries],\n",
    "        color='b',\n",
    "        marker='o',\n",
    "        #label=f'Ground-truth observed-entries {column_name[i]}'\n",
    "    )\n",
    "    \n",
    "    # Plot the missing entries (Ground-truth Missing)\n",
    "    axes[i].scatter(\n",
    "        time_indices[missing_entries],\n",
    "        ground_truth[missing_entries],\n",
    "        color='g',\n",
    "        marker='o',\n",
    "        #label=f'Ground-truth missing-entries {column_name[i]}'\n",
    "    )\n",
    "    \n",
    "    # Plot the missing entries (Ground-truth Missing)\n",
    "    axes[i].scatter(\n",
    "        time_indices[missing_entries],\n",
    "        imputed_values[missing_entries],\n",
    "        color='r',\n",
    "        marker='x',\n",
    "        #label=f'Imputed-entries {column_name[i]}'\n",
    "    )\n",
    "    \n",
    "    axes[i].set_xlabel('Time')\n",
    "    axes[i].set_ylabel(f'{column_name[i]}')\n",
    "    axes[i].grid(True)\n",
    "    axes[i].legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b07171-e6fe-4f4a-8c83-1f178234852f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
